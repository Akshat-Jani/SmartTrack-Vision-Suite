# -*- coding: utf-8 -*-
"""
Created on Thu Sep 18 15:33:07 2025

@author: acer
"""
# analyze.py
"""
SmartTrack Analytics (for metrics.csv)
--------------------------------------
Reads the frame-level metrics file generated by pipeline_tracker.py,
extracts statistics, and plots simple analytics.

Usage:
    python analyze.py path/to/metrics.csv
"""
#!/usr/bin/env python3
"""
pipeline_tracker.py
Simple, robust pipeline wrapper for Ultralytics YOLO track generator.

- Writes per-frame metrics to: <out_dir>/metrics.csv
- Optionally writes per-detection rows to: <out_dir>/detections.csv
- Uses configs from configs/run.yaml by default; CLI args can override.
"""

from pathlib import Path
import argparse
import json
import time
import csv
import yaml
from collections import Counter

# Ultralytics import (make sure ultralytics is installed in your env)
from ultralytics import YOLO


def run_track(cfg):
    # Resolve paths and create output directory
    src = Path(cfg["source"])
    run_name = cfg.get("name") or f"pipeline_{src.stem}"
    out_dir = Path(cfg["project"]) / run_name
    out_dir.mkdir(parents=True, exist_ok=True)

    print(f"[INFO] Starting run: {run_name}")
    print(f"[INFO] Source: {src}")
    print(f"[INFO] Out dir: {out_dir.resolve()}")

    # Load model
    model_path = cfg["model_path"]
    print(f"[INFO] Loading model from: {model_path}")
    model = YOLO(model_path)
    class_names = getattr(model, "names", {})

    # Prepare CSV paths
    metrics_path = out_dir / "metrics.csv"
    detections_path = out_dir / "detections.csv"  # optional detailed log

    # Open both CSVs (metrics always written; detections written if boxes exist)
    with open(metrics_path, "w", newline="", encoding="utf-8") as f_metrics, \
         open(detections_path, "w", newline="", encoding="utf-8") as f_dets:

        metrics_writer = csv.DictWriter(f_metrics, fieldnames=["frame", "fps", "num_tracks", "counts_json"])
        metrics_writer.writeheader()

        det_fieldnames = [
            "frame", "id", "cls_id", "cls_name", "conf",
            "x1", "y1", "x2", "y2", "fps", "video_width", "video_height"
        ]
        det_writer = csv.DictWriter(f_dets, fieldnames=det_fieldnames)
        det_writer.writeheader()

        # Tracking generator
        results_gen = model.track(
            source=str(src),
            tracker=str(cfg["tracker_cfg"]),
            save=True,
            conf=float(cfg.get("conf", 0.25)),
            project=str(cfg["project"]),
            name=run_name,
            exist_ok=True,
            verbose=bool(cfg.get("verbose", False)),
            show=bool(cfg.get("show", False)),
            stream=True,
        )

        frame_idx = 0
        t_prev = time.perf_counter()
        fps_ma = None

        print("[INFO] Entering frame loop...")
        for r in results_gen:
            # Basic FPS measurement
            t_now = time.perf_counter()
            fps_inst = 1.0 / max(1e-6, (t_now - t_prev))
            t_prev = t_now
            fps_ma = fps_inst if fps_ma is None else (0.9 * fps_ma + 0.1 * fps_inst)
            fps_val = round(fps_ma, 3) if fps_ma else round(fps_inst, 3)

            # Prepare counts and number of tracks
            counts = Counter()
            num_tracks = 0

            # r.boxes may be None or empty if no detections this frame
            boxes = getattr(r, "boxes", None)
            if boxes is not None and len(boxes) > 0:
                # class ids (may be a tensor) â€” handle safely
                try:
                    cls_arr = boxes.cls.cpu().numpy().astype(int)
                except Exception:
                    cls_arr = boxes.cls.numpy().astype(int)

                # ids (tracker IDs) may not exist for every model/tracker
                ids = getattr(boxes, "id", None)
                if ids is not None:
                    try:
                        ids_arr = ids.cpu().numpy()
                    except Exception:
                        ids_arr = ids.numpy()
                    num_tracks = int((ids_arr >= 0).sum())
                else:
                    ids_arr = [-1] * len(cls_arr)

                for cid in cls_arr:
                    cname = class_names.get(int(cid), str(int(cid)))
                    counts[cname] += 1

                # Try getting xyxy coords and confs; handle API differences
                try:
                    xyxy = boxes.xyxy.cpu().numpy()
                except Exception:
                    try:
                        xyxy = boxes.xyxy.numpy()
                    except Exception:
                        xyxy = None

                try:
                    confs = boxes.conf.cpu().numpy()
                except Exception:
                    try:
                        confs = boxes.conf.numpy()
                    except Exception:
                        confs = None

                # Try to infer the original frame size if available
                video_w = video_h = ""
                if hasattr(r, "orig_shape") and r.orig_shape is not None:
                    try:
                        # r.orig_shape commonly = (height, width, channels)
                        video_h, video_w = int(r.orig_shape[0]), int(r.orig_shape[1])
                    except Exception:
                        video_w = video_h = ""

                # Write one row per detection if coords are available
                if xyxy is not None and confs is not None:
                    for i in range(len(xyxy)):
                        x1, y1, x2, y2 = [float(v) for v in xyxy[i]]
                        row = {
                            "frame": int(frame_idx),
                            "id": int(ids_arr[i]) if ids_arr is not None else -1,
                            "cls_id": int(cls_arr[i]),
                            "cls_name": class_names.get(int(cls_arr[i]), str(int(cls_arr[i]))),
                            "conf": float(confs[i]),
                            "x1": x1, "y1": y1, "x2": x2, "y2": y2,
                            "fps": fps_val,
                            "video_width": int(video_w) if video_w != "" else "",
                            "video_height": int(video_h) if video_h != "" else ""
                        }
                        det_writer.writerow(row)
                else:
                    # If coordinates missing, skip per-detection rows but keep counts
                    pass

            # Write per-frame summary (always)
            metrics_writer.writerow({
                "frame": frame_idx,
                "fps": fps_val,
                "num_tracks": num_tracks,
                "counts_json": json.dumps(counts, ensure_ascii=False)
            })

            # Flush to disk so files are visible while running
            f_metrics.flush()
            f_dets.flush()

            # Helpful debug print (minimal)
            if frame_idx % 50 == 0:
                print(f"[INFO] frame={frame_idx}, fps={fps_val}, num_tracks={num_tracks}")

            frame_idx += 1

        print(f"[OK] Completed run. Outputs saved in: {out_dir.resolve()}")

    # files closed automatically by with-context


def load_config(config_path):
    with open(config_path, "r") as f:
        cfg = yaml.safe_load(f)
    return cfg


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="SmartTrack pipeline tracker runner")
    parser.add_argument("--config", default="configs/run.yaml", help="path to run.yaml")
    parser.add_argument("--source", default=None, help="override source (video or camera)")
    parser.add_argument("--model_path", default=None, help="override model path")
    parser.add_argument("--tracker_cfg", default=None, help="override tracker config")
    parser.add_argument("--project", default=None, help="override project output folder")
    parser.add_argument("--name", default=None, help="override run name")
    args = parser.parse_args()

    cfg = load_config(args.config)

    # apply CLI overrides (only if provided)
    if args.source:
        cfg["source"] = args.source
    if args.model_path:
        cfg["model_path"] = args.model_path
    if args.tracker_cfg:
        cfg["tracker_cfg"] = args.tracker_cfg
    if args.project:
        cfg["project"] = args.project
    if args.name:
        cfg["name"] = args.name

    # minimal validation
    if "source" not in cfg or "model_path" not in cfg or "project" not in cfg:
        print("[ERROR] Missing required fields in config. Please set 'source', 'model_path', and 'project'.")
        raise SystemExit(1)

    run_track(cfg)

